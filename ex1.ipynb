{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will practice the basic steps to fit and to use a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03402377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Users\\verba\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_2          16 KB\n",
      "    ca-certificates-2025.7.15  |       haa95532_0         127 KB\n",
      "    certifi-2025.8.3           |  py310haa95532_0         160 KB\n",
      "    libxgboost-3.0.1           |       h585ebfc_0         2.7 MB\n",
      "    py-xgboost-3.0.1           |  py310haa95532_0         309 KB\n",
      "    ucrt-10.0.22621.0          |       haa95532_0         620 KB\n",
      "    vc14_runtime-14.44.35208   |      h4927774_10         825 KB\n",
      "    vs2015_runtime-14.44.35208 |      ha6b5a95_10          19 KB\n",
      "    xgboost-3.0.1              |  py310haa95532_0          14 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  pkgs/main/win-64::_py-xgboost-mutex-2.0-cpu_2 \n",
      "  libxgboost         pkgs/main/win-64::libxgboost-3.0.1-h585ebfc_0 \n",
      "  py-xgboost         pkgs/main/win-64::py-xgboost-3.0.1-py310haa95532_0 \n",
      "  ucrt               pkgs/main/win-64::ucrt-10.0.22621.0-haa95532_0 \n",
      "  vc14_runtime       pkgs/main/win-64::vc14_runtime-14.44.35208-h4927774_10 \n",
      "  xgboost            pkgs/main/win-64::xgboost-3.0.1-py310haa95532_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2025.2.25-haa95532_0 --> 2025.7.15-haa95532_0 \n",
      "  certifi                         2025.1.31-py310haa95532_0 --> 2025.8.3-py310haa95532_0 \n",
      "  vc                                        14.2-h21ff451_1 --> 14.42-haa95532_5 \n",
      "  vs2015_runtime                     14.27.29016-h5e58377_2 --> 14.44.35208-ha6b5a95_10 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "_py-xgboost-mutex-2. | 16 KB     |            |   0% \n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "py-xgboost-3.0.1     | 309 KB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xgboost-3.0.1        | 14 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-3.0.1     | 2.7 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2025.8.3     | 160 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.44 | 19 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    | 5          |   6% \u001b[A\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    | #          |  10% \u001b[A\u001b[A\n",
      "_py-xgboost-mutex-2. | 16 KB     | ########## | 100% \n",
      "_py-xgboost-mutex-2. | 16 KB     | ########## | 100% \n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    | #######1   |  72% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-3.0.1     | 2.7 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.44 | 19 KB     | ########3  |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2025.8.3     | 160 KB    | #          |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-3.0.1     | 2.7 MB    | ##5        |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.44 | 19 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "vc14_runtime-14.44.3 | 825 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | #2         |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 620 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "py-xgboost-3.0.1     | 309 KB    | 5          |   5% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2025.8.3     | 160 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2025.8.3     | 160 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-3.0.1     | 2.7 MB    | #######9   |  80% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xgboost-3.0.1        | 14 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "py-xgboost-3.0.1     | 309 KB    | ###1       |  31% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xgboost-3.0.1        | 14 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-3.0.1     | 2.7 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "py-xgboost-3.0.1     | 309 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "py-xgboost-3.0.1     | 309 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 25.7.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.7.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train = pd.read_csv(\"ex1_train.csv\", header=None)\n",
    "X_test = pd.read_csv(\"ex1_test.csv\", header=None)\n",
    "y_train = pd.read_csv(\"ex1_class_train.csv\", header=None)\n",
    "y_test = pd.read_csv(\"ex1_class_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Default XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Fit the model and predict for test data in the following cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\verba\\anaconda3\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [10:23:25] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# 1) create an XGBoost classifier instance\n",
    "classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "# 2) fit the classifier using X_train and y_train\n",
    "classifier.fit(X_train, y_train.values.ravel())\n",
    "# 3) make prediction over X_test. The prediction output should be named y_pred_default\n",
    "y_pred_default = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Model Performance:\n",
      "Accuracy: 0.7032\n",
      "Precision: 0.7216\n",
      "Recall: 0.7186\n",
      "F1 Score: 0.7201\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the default model\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "precision_default = precision_score(y_test, y_pred_default)\n",
    "recall_default = recall_score(y_test, y_pred_default)\n",
    "f1_default = f1_score(y_test, y_pred_default)\n",
    "\n",
    "print(\"Default Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_default:.4f}\")\n",
    "print(f\"Precision: {precision_default:.4f}\")\n",
    "print(f\"Recall: {recall_default:.4f}\")\n",
    "print(f\"F1 Score: {f1_default:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should achieve F1 score>0.65 to pass Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Hyperparameter Tuning with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define candidate hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "# These are the hyperparameters we will tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Find the best hyperparameters and use them to fit an improved classifier in the following cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\verba\\anaconda3\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:30:52] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# 1) use GridSearchCV to find the best hyperparameters\n",
    "# Creating the GridSearchCV instance\n",
    "# estimator is the classifier instance, param_grid is the hyperparameter grid\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid,\n",
    "                            scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "# 2) fit an XGBoost classifier using the best hyperparameters\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "# 3) make prediction over X_test. The prediction output should be named y_pred_tuned\n",
    "y_pred_tuned = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model Performance:\n",
      "Accuracy: 0.7186\n",
      "Precision: 0.7276\n",
      "Recall: 0.7519\n",
      "F1 Score: 0.7396\n",
      "Improvement in F1 Score: 0.0195\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the tuned model\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "precision_tuned = precision_score(y_test, y_pred_tuned)\n",
    "recall_tuned = recall_score(y_test, y_pred_tuned)\n",
    "f1_tuned = f1_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(\"Tuned Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_tuned:.4f}\")\n",
    "print(f\"Precision: {precision_tuned:.4f}\")\n",
    "print(f\"Recall: {recall_tuned:.4f}\")\n",
    "print(f\"F1 Score: {f1_tuned:.4f}\")\n",
    "\n",
    "# Analysis\n",
    "print(f\"Improvement in F1 Score: {f1_tuned - f1_default:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass Part 2, your new F1 score should be higher 0.65 and the one in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvements made by tuning hyperparameters:\n",
      "Accuracy: 0.0155\n",
      "Precision: 0.0060\n",
      "Recall: 0.0334\n",
      "F1 Score: 0.0195\n"
     ]
    }
   ],
   "source": [
    "# Improvements\n",
    "print(\"Improvements made by tuning hyperparameters:\")\n",
    "print(f\"Accuracy: {accuracy_tuned - accuracy_default:.4f}\")\n",
    "print(f\"Precision: {precision_tuned - precision_default:.4f}\")\n",
    "print(f\"Recall: {recall_tuned - recall_default:.4f}\")\n",
    "print(f\"F1 Score: {f1_tuned - f1_default:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
